# Usage Guide

## Project configuration

All pipeline settings live in `config/pipeline.yaml`. The most common edits are:

- **Data source versions and URLs**
  - BindingDB version and subset
  - LINCS compound info release
  - JUMP-CP metadata release
  - DeepChem dataset URLs
  - AnnotationDB endpoint
- **BindingDB filtering**
  - Organism allowlist
  - Columns retained in the cleaned export
- **Fingerprint parameters**
  - Morgan radii and vector dimensions

If you change versions or URLs, update `docs/data_sources.md` so the provenance stays current.

## Data locations

The pipeline writes data into three main locations:

- `data/rawdata/`: raw downloads (BindingDB, LINCS, JUMP-CP, AnnotationDB JSONL).
- `data/procdata/`: processed datasets (colData, experiments, fingerprints).
- `data/results/`: final HDD_v1 output (`HDD_v1.RDS`).

Raw and processed files are not tracked in Git, so make sure you archive them externally if you need to preserve a run.

## Running the pipeline

Install dependencies with Pixi:

```bash
pixi install
```

Run Snakemake from the repository root:

```bash
pixi run snakemake -c 1
```

## Quality control

Render the QC report after the pipeline has produced `HDD_v1.RDS`:

```bash
pixi run knit_qc
```

The report is saved to `qc/hdd_quality_control.html`.
